{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0652f264-b2c3-43b2-9310-7c00e50e7cdc",
   "metadata": {},
   "source": [
    "# XGBoost.Dask in many threads\n",
    "\n",
    "Sometimes we want to train many large XGBoost models in parallel.  We do so in this example with ...\n",
    "\n",
    "1.  The `xgboost.dask` project to do large training runs\n",
    "2.  Optuna to do hyper-parameter-optimization\n",
    "3.  A thread pool, to run many of these in parallel\n",
    "4.  Coiled to launch Dask clusters (but you could swap in your favorite Dask deployment technology as you like)\n",
    "\n",
    "Using `xgboost.dask` from many threads tooks a couple of small tweaks across projects.  This notebook resulted in the following PRs and issues:\n",
    "\n",
    "-  https://github.com/dask/distributed/issues/7377\n",
    "-  https://github.com/dask/dask/pull/9723\n",
    "-  https://github.com/dask/distributed/pull/7369\n",
    "-  https://github.com/dmlc/xgboost/pull/8558 (mostly cosmetic, not necessary)\n",
    "-  Also something in Coiled to allow package_sync to be thread-safe, should be released by 2022-12-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b929987-5089-4c13-be35-c1812d65fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from distributed import Client\n",
    "import dask.dataframe as dd\n",
    "from coiled import Cluster\n",
    "import coiled\n",
    "\n",
    "import optuna\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "from dask_ml.metrics import mean_squared_error as lazy_mse\n",
    "import xgboost as xgb\n",
    "from xgboost.dask import DaskDMatrix\n",
    "\n",
    "from dask_ml.datasets import make_classification_df\n",
    "from dask_ml.model_selection import train_test_split, KFold\n",
    "from dask_ml.preprocessing import OneHotEncoder\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "from s3fs import S3FileSystem\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780815b1-fa82-43c1-93c0-572f0f6182c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask, coiled\n",
    "print(\"coiled:\", coiled.__version__)\n",
    "print(\"dask:\", dask.__version__)\n",
    "print(\"dask.distributed:\", dask.distributed.__version__)\n",
    "print(\"optuna:\", optuna.__version__)\n",
    "print(\"xgboost:\", xgb.__version__)\n",
    "print(\"coiled:\", coiled.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd461c3-e551-420a-a3e1-1ca2515bb613",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd3bf0-f8c2-4240-b12b-8ee6e4c772c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOROUGH_MAPPING = {\n",
    "    \"Manhattan\": \"Superborough 1\",\n",
    "    \"Bronx\": \"Superborough 1\",\n",
    "    \"EWR\": \"Superborough 1\",\n",
    "    \"Brooklyn\": \"Superborough 2\",\n",
    "    \"Queens\": \"Superborough 2\",\n",
    "    \"Staten Island\": \"Superborough 3\",\n",
    "    \"Unknown\": \"Unknown\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8574767-4b4c-4c82-a31d-448bd2d6ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print(\"loading data\")\n",
    "    to_exclude=[\"string\", \"category\", \"object\"]\n",
    "    ddf= dd.read_parquet(\"s3://prefect-dask-examples/nyc-uber-lyft/processed_files.parquet\")\n",
    "    ddf = ddf.assign(accessible_vehicle = 1)\n",
    "    print(\"Make accessible feature\")\n",
    "    ddf.accessible_vehicle = ddf.accessible_vehicle.where(ddf.on_scene_datetime.isnull(),0)  # Only applies if the vehicle is wheelchair accessible\n",
    "    ddf = ddf.assign(pickup_month = ddf.pickup_datetime.dt.month)\n",
    "    ddf = ddf.assign(pickup_dow = ddf.pickup_datetime.dt.dayofweek)\n",
    "    ddf = ddf.assign(pickup_hour = ddf.pickup_datetime.dt.hour)\n",
    "    \n",
    "    ddf = ddf.drop(columns=['on_scene_datetime', 'request_datetime',\n",
    "                            'pickup_datetime', 'dispatching_base_num',\n",
    "                            'originating_base_num', 'shared_request_flag',\n",
    "                           'shared_match_flag','dropoff_datetime',\n",
    "                           ]\n",
    "                  )\n",
    "\n",
    "    ddf = ddf.dropna(how=\"any\")\n",
    "    ddf = ddf.repartition(partition_size=\"128MB\")\n",
    "    ddf = ddf.reset_index(drop=True)\n",
    "\n",
    "    original_rowcount = len(ddf.index)\n",
    "\n",
    "    # Remove outliers\n",
    "    # Based on our earlier EDA, we will set the lower bound at zero, which is consistent with our\n",
    "    # domain knowledge that no trip should have a duration less than zero.  We calculate the upper_bound\n",
    "    # and filter the IQR\n",
    "    lower_bound = 0\n",
    "    Q3 = ddf['trip_time'].quantile(0.75)\n",
    "    upper_bound = Q3 + (1.5*(Q3 - lower_bound))\n",
    "    \n",
    "    ddf = ddf.loc[(ddf['trip_time'] >= lower_bound) & (ddf['trip_time'] <= upper_bound)]\n",
    "    \n",
    "    ddf = ddf.repartition(partition_size=\"128MB\")\n",
    "    print(f\"Fraction of dataset left after removing outliers:  {len(ddf.index) / original_rowcount}\")\n",
    "\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af41ab-17d9-47fd-81b8-7fda50bf8abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_superborough(df):\n",
    "    PUSuperborough = [BOROUGH_MAPPING.get(i) for i in df.PUBorough.tolist()]\n",
    "    DOSuperborough = [BOROUGH_MAPPING.get(i) for i in df.DOBorough.tolist()]\n",
    "    cross_superborough = [\"N\" if i==j else \"Y\" for (i,j) in zip(PUSuperborough, DOSuperborough)]\n",
    "    return df.assign(CrossSuperborough = cross_superborough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51335c28-de29-4a23-ba2e-e7d389acff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_taxi_data(ddf):\n",
    "    print(\"Load taxi data\")\n",
    "    taxi_df = pd.read_csv(\"data/taxi+_zone_lookup.csv\", usecols=[\"LocationID\", \"Borough\"])\n",
    "\n",
    "    ddf = dd.merge(ddf, taxi_df, left_on=\"PULocationID\", right_on=\"LocationID\", how=\"inner\")\n",
    "    ddf = ddf.rename(columns={\"Borough\": \"PUBorough\"})\n",
    "    ddf = ddf.drop(columns=\"LocationID\")\n",
    "\n",
    "    ddf = dd.merge(ddf, taxi_df, left_on=\"DOLocationID\", right_on=\"LocationID\", how=\"inner\")\n",
    "    ddf = ddf.rename(columns={\"Borough\": \"DOBorough\"})\n",
    "    ddf = ddf.drop(columns=\"LocationID\")  \n",
    "    \n",
    "    print(\"Make superboroughs\")\n",
    "    ddf = ddf.map_partitions(lambda df: get_superborough(df))\n",
    "    ddf['airport_fee'] = ddf['airport_fee'].replace(\"None\", 0)\n",
    "    ddf['airport_fee'] = ddf['airport_fee'].replace('nan', 0)\n",
    "    ddf['airport_fee'] = ddf['airport_fee'].astype(float)\n",
    "    ddf['airport_fee'] = ddf['airport_fee'].fillna(0)\n",
    "\n",
    "    print(\"Drop unneeded cols\")\n",
    "    to_drop = ['base_passenger_fare', 'bcf', 'sales_tax', 'tips',\n",
    "               'driver_pay', 'access_a_ride_flag', 'wav_match_flag'\n",
    "              ]\n",
    "    ddf2 = ddf.drop(columns=to_drop)\n",
    "    ddf2 = ddf2.repartition(partition_size=\"100MB\")\n",
    "\n",
    "    print(\"Make categoricals\")\n",
    "    categories = ['hvfhs_license_num', 'PULocationID', \"DOLocationID\", 'wav_request_flag',\n",
    "                  'accessible_vehicle', 'pickup_month', 'pickup_dow', 'pickup_hour', \n",
    "                  'PUBorough', 'DOBorough', 'CrossSuperborough'\n",
    "                 ]\n",
    "    ddf2[categories] = ddf2[categories].astype('category')\n",
    "    ddf2 = ddf2.categorize(columns=categories)\n",
    "    ddf2 = ddf2.repartition(partition_size=\"128MB\")\n",
    "    return ddf2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a8954-1f15-41a5-81f2-2d042fa860f9",
   "metadata": {},
   "source": [
    "## Test Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abab0dd-e0ed-4763-b740-5bc4cf0ecb0f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster = coiled.Cluster(\n",
    "    worker_vm_types=[\"m6i.4xlarge\"],\n",
    "    scheduler_vm_types=[\"m6i.2xlarge\"],\n",
    "    package_sync=True, # copy local packages,\n",
    "    name=\"dask-engineering-f799f650-0\",\n",
    "    shutdown_on_close=True,  # reuse cluster across runs\n",
    "    show_widget=False,\n",
    "    n_workers=20,\n",
    "    use_best_zone=True,\n",
    "    account=\"dask-engineering\",\n",
    "    )\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a211755-d0f2-410f-9089-892cf09ad488",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616048f-3b09-458a-9e97-8fa04b3500f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddf = load_data()\n",
    "ddf = make_taxi_data(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554e6e0-0c08-4f4e-ab2e-408abfeb2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e57258-b913-4bf1-bf42-6c919f18de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02f30d-4414-4447-9e84-fa76df9c2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55aa35-3bc7-45d1-b821-edd64e0d73ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.to_parquet(\"s3://prefect-dask-examples/nyc-uber-lyft/feature_table.parquet\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ac5f8-a94b-484b-bd7c-b256d1272d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa882b6-fd67-413f-af4c-99b3a438d406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398a004-e903-4d0d-bf3b-90aad465bb72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
