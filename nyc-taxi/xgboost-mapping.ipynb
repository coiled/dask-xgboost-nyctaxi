{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0652f264-b2c3-43b2-9310-7c00e50e7cdc",
   "metadata": {},
   "source": [
    "# XGBoost.Dask in many threads\n",
    "\n",
    "Sometimes we want to train many large XGBoost models in parallel.  We do so in this example with ...\n",
    "\n",
    "1.  The `xgboost.dask` project to do large training runs\n",
    "2.  Optuna to do hyper-parameter-optimization\n",
    "3.  A thread pool, to run many of these in parallel\n",
    "4.  Coiled to launch Dask clusters (but you could swap in your favorite Dask deployment technology as you like)\n",
    "\n",
    "Using `xgboost.dask` from many threads tooks a couple of small tweaks across projects.  This notebook resulted in the following PRs and issues:\n",
    "\n",
    "-  https://github.com/dask/distributed/issues/7377\n",
    "-  https://github.com/dask/dask/pull/9723\n",
    "-  https://github.com/dask/distributed/pull/7369\n",
    "-  https://github.com/dmlc/xgboost/pull/8558 (mostly cosmetic, not necessary)\n",
    "-  Also something in Coiled to allow package_sync to be thread-safe, should be released by 2022-12-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b929987-5089-4c13-be35-c1812d65fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from distributed import Client\n",
    "import dask.dataframe as dd\n",
    "from coiled import Cluster\n",
    "import coiled\n",
    "\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from dask_ml.metrics import mean_squared_error as lazy_mse\n",
    "import xgboost as xgb\n",
    "from xgboost.dask import DaskDMatrix\n",
    "\n",
    "from dask_ml.datasets import make_classification_df\n",
    "from dask_ml.model_selection import train_test_split, KFold\n",
    "from dask_ml.preprocessing import OneHotEncoder\n",
    "import dask.array as da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780815b1-fa82-43c1-93c0-572f0f6182c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coiled: 0.2.58\n",
      "dask: 2022.12.0+13.g0d8e12be\n",
      "dask.distributed: 2022.12.0+17.gf8302593\n",
      "optuna: 3.1.0.dev\n",
      "xgboost: 1.7.2\n",
      "coiled: 0.2.58\n"
     ]
    }
   ],
   "source": [
    "import dask, coiled\n",
    "print(\"coiled:\", coiled.__version__)\n",
    "print(\"dask:\", dask.__version__)\n",
    "print(\"dask.distributed:\", dask.distributed.__version__)\n",
    "print(\"optuna:\", optuna.__version__)\n",
    "print(\"xgboost:\", xgb.__version__)\n",
    "print(\"coiled:\", coiled.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a784f39-f7fb-4274-889f-bd8edcc2489a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting run\n"
     ]
    }
   ],
   "source": [
    "cluster_name = \"eda\"\n",
    "cluster = coiled.Cluster(\n",
    "    worker_vm_types=[\"m6i.4xlarge\"],\n",
    "    scheduler_vm_types=[\"m6i.2xlarge\"],\n",
    "    package_sync=True, # copy local packages,\n",
    "    name=cluster_name,\n",
    "    shutdown_on_close=False,  # reuse cluster across runs\n",
    "    show_widget=False,\n",
    "    n_workers=6,\n",
    "    use_best_zone=True,\n",
    "    account=\"dask-engineering\",\n",
    "    backend_options={\"region\": \"us-east-2\", \"spot\": True, \"spot_on_demand_fallback\": True}\n",
    "    )\n",
    "\n",
    "print(\"starting run\")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd461c3-e551-420a-a3e1-1ca2515bb613",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8574767-4b4c-4c82-a31d-448bd2d6ae71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "Make accessible feature\n",
      "Completed data preprocessing in 0:01:37.987823 with 726579128 rows\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from s3fs import S3FileSystem\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    start = datetime.datetime.now()\n",
    "    print(\"loading data\")\n",
    "    to_exclude=[\"string\", \"category\", \"object\"]\n",
    "    ddf= dd.read_parquet(\"s3://prefect-dask-examples/nyc-uber-lyft/processed_files.parquet\").select_dtypes(exclude=to_exclude)\n",
    "    # ddf = ddf.drop(columns=[\"base_passenger_fare\", \"sales_tax\", \"bcf\", \"congestion_surcharge\", \"tips\", \"driver_pay\", \"dropoff_datetime\"])\n",
    "    ddf = ddf.assign(accessible_vehicle = 1)\n",
    "    print(\"Make accessible feature\")\n",
    "    ddf.accessible_vehicle = ddf.accessible_vehicle.where(ddf.on_scene_datetime.isnull(),0)  # Only applies if the vehicle is wheelchair accessible\n",
    "    ddf = ddf.assign(request_dow = ddf.request_datetime.dt.dayofweek)\n",
    "    ddf = ddf.assign(pickup_datetime_dow = ddf.pickup_datetime.dt.dayofweek)\n",
    "    ddf = ddf.assign(request_hour = ddf.request_datetime.dt.hour)\n",
    "    ddf = ddf.assign(pickup_datetime_hour = ddf.pickup_datetime.dt.hour)\n",
    "    ddf = ddf.drop(columns=['on_scene_datetime', 'request_datetime', 'pickup_datetime'])\n",
    "\n",
    "    ddf = ddf.dropna(how=\"any\")\n",
    "    ddf = ddf.repartition(partition_size=\"128MB\")\n",
    "    ddf = ddf.reset_index(drop=True)\n",
    "\n",
    "    categories = [\"request_dow\", \"request_hour\", \"pickup_datetime_hour\", \"pickup_datetime_dow\"]\n",
    "    for cat in categories:\n",
    "        ddf[cat] = ddf[cat].astype('category')\n",
    "\n",
    "    # Ideally we would categorize the data here, but splitting\n",
    "    # causes us to lose that information, so its a wasted operation\n",
    "\n",
    "    print(f\"Completed data preprocessing in {datetime.datetime.now() - start} with {len(ddf.index)} rows\")\n",
    "    return ddf\n",
    "ddf = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f999265f-effe-4ccf-9e1b-dc687e254798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>bcf</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>accessible_vehicle</th>\n",
       "      <th>request_dow</th>\n",
       "      <th>pickup_datetime_dow</th>\n",
       "      <th>request_hour</th>\n",
       "      <th>pickup_datetime_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-23 07:21:17</td>\n",
       "      <td>47</td>\n",
       "      <td>152</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1279</td>\n",
       "      <td>17.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-23 06:59:44</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>4.55</td>\n",
       "      <td>860</td>\n",
       "      <td>19.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.75</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-23 06:59:58</td>\n",
       "      <td>249</td>\n",
       "      <td>161</td>\n",
       "      <td>2.61</td>\n",
       "      <td>809</td>\n",
       "      <td>13.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-23 06:57:58</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>2.40</td>\n",
       "      <td>420</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-23 06:39:26</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>2.88</td>\n",
       "      <td>504</td>\n",
       "      <td>9.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  trip_time  \\\n",
       "0 2019-04-23 07:21:17            47           152        4.32       1279   \n",
       "1 2019-04-23 06:59:44           230           226        4.55        860   \n",
       "2 2019-04-23 06:59:58           249           161        2.61        809   \n",
       "3 2019-04-23 06:57:58            23            23        2.40        420   \n",
       "4 2019-04-23 06:39:26            23            23        2.88        504   \n",
       "\n",
       "   base_passenger_fare  tolls   bcf  sales_tax  congestion_surcharge  tips  \\\n",
       "0                17.05    0.0  0.43       1.51                  0.00   0.0   \n",
       "1                19.78    0.0  0.49       1.75                  2.75   7.0   \n",
       "2                13.24    0.0  0.33       1.17                  2.75   1.0   \n",
       "3                 8.24    0.0  0.21       0.73                  0.00   0.0   \n",
       "4                 9.98    0.0  0.25       0.89                  0.00   1.0   \n",
       "\n",
       "   driver_pay  accessible_vehicle request_dow pickup_datetime_dow  \\\n",
       "0       15.33                   0           1                   1   \n",
       "1       19.11                   0           1                   1   \n",
       "2       10.57                   0           1                   1   \n",
       "3        6.41                   1           1                   1   \n",
       "4        8.33                   0           1                   1   \n",
       "\n",
       "  request_hour pickup_datetime_hour  \n",
       "0            6                    6  \n",
       "1            6                    6  \n",
       "2            6                    6  \n",
       "3            6                    6  \n",
       "4            6                    6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18c7bc4d-e961-473b-9923-7ce94a4d7658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       47\n",
       "1      230\n",
       "2      249\n",
       "3       23\n",
       "4       39\n",
       "      ... \n",
       "258      2\n",
       "259    110\n",
       "260    199\n",
       "261    264\n",
       "262    105\n",
       "Name: PULocationID, Length: 263, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ddf['PULocationID'].unique().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20502d1a-7a18-4045-8958-a01550d914da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      152\n",
       "1      226\n",
       "2      161\n",
       "3       23\n",
       "4       39\n",
       "      ... \n",
       "259    264\n",
       "260    110\n",
       "261    104\n",
       "262    105\n",
       "263    199\n",
       "Name: DOLocationID, Length: 264, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 22:26:52,149 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "2022-12-23 22:27:30,880 - distributed.deploy.cluster - WARNING - Failed to sync cluster info multiple times - perhaps there's a connection issue? Error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/greghayes/mambaforge/envs/xgboost_test/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 498, in connect\n",
      "    stream = await self.client.connect(\n",
      "  File \"/Users/greghayes/mambaforge/envs/xgboost_test/lib/python3.10/site-packages/tornado/tcpclient.py\", line 275, in connect\n",
      "    af, addr, stream = await connector.start(connect_timeout=timeout)\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/greghayes/mambaforge/envs/xgboost_test/lib/python3.10/asyncio/tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/greghayes/mambaforge/envs/xgboost_test/lib/python3.10/site-packages/distributed/comm/core.py\", line 291, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/Users/greghayes/mambaforge/envs/xgboost_test/lib/python3.10/asyncio/tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/greghayes/mambaforge/envs/xgboost_test/lib/python3.10/site-packages/distributed/deploy/cluster.py\", line 155, in _sync_cluster_info\n",
      "    await self.scheduler_comm.set_metadata(\n",
      "  File \"/Users/greghayes/mambaforge/envs/xgboost_test/lib/python3.10/site-packages/distributed/core.py\", line 1138, in send_recv_from_rpc\n",
      "    comm = await self.live_comm()\n",
      "  File \"/Users/greghayes/mambaforge/envs/xgboost_test/lib/python3.10/site-packages/distributed/core.py\", line 1097, in live_comm\n",
      "    comm = await connect(\n",
      "  File \"/Users/greghayes/mambaforge/envs/xgboost_test/lib/python3.10/site-packages/distributed/comm/core.py\", line 317, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tls://3.129.19.38:8786 after 30 s\n",
      "WARNING:root:error sending AWS credentials to cluster: Timed out trying to connect to tls://3.129.19.38:8786 after 30 s\n"
     ]
    }
   ],
   "source": [
    "ddf['DOLocationID'].unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a324777-58f4-4e3e-a19f-8cb4690dcb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
